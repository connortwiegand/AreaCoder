---
title: "Fastest 100 metre times"
author: "Connor Wiegand"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    theme: yeti
    highlight: haddock
    toc: yes
    toc_depth: 3
    toc_float: yes
    keep_md: yes
always_allow_html: true
---

```{r setup, include=FALSE}
## This next line sets the default behaviour for all R chunks in the .Rmd document.
## I recomend you take a look here: https://rmarkdown.rstudio.com/authoring_rcodechunks.html
knitr::opts_chunk$set(echo = TRUE, cache = T, error = TRUE, dpi=300)
```

## Background

In class, we practiced webscraping with the Wikipedia page on the [Men's 100 metres world record progression](http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression). For this assignment, we're going to continue with a similar theme, except we won't only be limiting ourselves to world record times. The page that we're scraping will also have a few complications that require extra (or at least different) steps.

Here is the webpage: **[All-time men's best 100m](http://www.alltime-athletics.com/m_100ok.htm)**.

*<b>Note:</b> You are welcome to use the [women's all-time best 100m times](http://www.alltime-athletics.com/w_100ok.htm) if you prefer. However, please be aware that you may (will?) have to adjust some of the specific hints below. It will be become more obvious why once we get to the prediction section of the assignment.*

Now is good time to load any packages that you will be needing, as well as set your preferred plotting theme, etc. 

```{r libs, cache=F, message=F}
## Load your packages here, e.g.
pacman::p_load(rvest, readr, tidyverse, lubridate, magrittr, zoo, data.table, sf, rnaturalearth, rgeos, leaflet)
```


## 1) Read in the data

Take a look at the [webpage](http://www.alltime-athletics.com/m_100ok.htm) in your browser. We only want the information contained in the main table at the top (i.e. ignore the rolling starts, manual timing, etc.) Read this table into R and call the resulting object `m100_wp`.

*Hint: In class, we practiced identifying the correct HMTL elements with CSS selectors and SelectorGadget. However, you will almost certainly find it easier / more precise to scrape the table in this example via its XPath. Use your browser's "Inspect" functionality to find and copy over this XPath. Remember to specify the "xpath" argument (instead of the default "css") when pulling this information into R, i.e. `rvest::html_element(xpath = "XPATH_HERE")`.*

```{r read}
m100 = read_html("http://www.alltime-athletics.com/m_100ok.htm")
m100_wp <- html_element(m100, xpath = '/html/body/center[3]/pre/text()[1]')
```

## 2) Convert to a data frame


### 2.1) Try parsing with `rvest::html_table()`

With the Wikipedia example from class, we were able to parse an HTML table into a data frame simply by using `rvest::html_table()`. What happens if you try that here?

```{r html_table}
html_table(m100_wp)
```

### 2.2. Try parsing with `rvest::html_text()`

Unfortunately, the HTML object that we've read into R is old-school text. Luckily, we can still extract this text pretty easily into an R string. Do that and name the resulting object `m100_text`. Show me the first 1000 characters.

*Hint: The `head()` function works by elements, not characters. So you'll need some other function to show the first 1000 characters.*
```{r}
m100_text <- html_text(m100_wp)
substr(m100_text, 1, 1000)
```

### 2.3. Convert to fixed-width format

So we basically have one loooong string. How, then, should we convert it to a data frame? The clue has already been given to you in the subheading of this section, but you should have noticed that fixed-width format of the data anyway from the web page itself. Use that information to convert the string into a data frame, which I want you to call `m100`. 

What does your resulting `m100` data frame look like? (Make sure that you "print" it so that I can see it too.)

*Hint: See the `?readr::read_fwf` help documentation. Pay particular attention to the option of guessing the fixed column positions based on the the position of empty columns. (See the Details and Examples sections.). Don't worry about specifying column names yet.*

```{r fwf}
m100 <- read_fwf(m100_text, fwf_empty(m100_text, n = 100))
m100
```

## 3) Inspect and fix

### 3.1) Fix athlete names

Our `read_fwf()` call has had some trouble correctly identifying athlete names; particularly those with middle names or double-barreled surnames. This has also led to a mostly empty column in the data frame.

How many entries/athletes have been affected? Fix the issue by concatenating (uniting) the relevant columns and tidying up afterwards.

*Hint: In an ideal world, we would fill in the missing letters of the affected athletes, e.g. Leonard Myles-Mil<b>L</b>s or Kareem Streete-Tho<b>M</b>pson. However, that requires some tedious ifelse work, which I'm not worried about testing here. So just ignore any resulting misspellings that arise during the unite process.*

```{r melt}
n.na <- sum(is.na(m100[,5]))

#Setting the tokenizer to 1000 fixes both ranks and name issues
m100 <- read_fwf(m100_text, fwf_empty(m100_text, n = 1000))
m100 <- as.data.frame(m100)
```
**It looks like `n.na` names are affected, and all ranks starting at 109 were affected.**

### 3.2) Assign column names

You should now (hopefully) have nine columns. Assign them the following names: `c("rank", "time", "windspeed", "athlete", "country", "dob", "race_rank", "location", "date")`.

```{r col_names}
colnames(m100) <- c("rank", "time", "windspeed", "athlete", "country", "dob", "race_rank", "location", "date")
```

### 3.4 Convert columns to correct classes

Finally, convert your columns to the correct classes. Date columns should be converted to dates, numeric columns should be converted to numeric, etc.

*Hint: Check, but you should be able to ignore the few parsing failures that occur with converting date columns.*

```{r col_class}
m100 %<>% mutate(dob = zoo::as.Date(dob, format = "%d.%m.%y"))
m100 %<>% mutate(date = zoo::as.Date(date, format = "%d.%m.%Y"))

#Unfortunately, now we have dates in the future
#Note: if we use lubridate::as.Date, it will put both "date" and "dob" 60's dates in the 2060's
#zoo:as.Date only does this for dob
m100 %<>% mutate(dob = 
                   if_else(as.numeric(year(dob))<2021,
                           dob,
                           dob-years(100))
                )

#I want to convert the "time" column to be numeric (rather than a period object)
#Some of the times have a letter in them, which I have decided just to remove
m100 %<>% mutate(time = gsub("[A-Z]", "", m100[, "time"]) %>% as.numeric())

#windspeed: set as numeric, set NAs to 0
m100 %<>% mutate(windspeed = as.numeric(windspeed))
m100 %<>% mutate(windspeed = coalesce(windspeed, 0))

#all other class are of the correct types
sapply(m100, class)

```


## 4) Plot the data

Plot the data, with the race date on the x-axis and time on the y-axis. Highlight Usain Bolt's times in red.
```{r simple_plot}
m100 %>% ggplot() + 
  geom_point(aes(x = as.Date(date), y = time)) + 
  geom_point(subset(m100, athlete == "Usain Bolt"), mapping = aes(x = date, y = time, color = "red")) + 
  scale_color_manual(values = "red", labels = "Usain Bolt") +
  labs(title = "100-Meter Run Times", x = "Date", y= "Time")
```


## 5) Subset to fastest times per year

It's hard to fit a sensible model to the above data. What might make more sense is to think of 100 metre times as following some kind of (approximately) deterministic process over the years. Subset the data to the fastest time recorded in each year. Call this new data frame `m100_yr` and then repeat the plot above, again highlighting Usain Bolt's times.
```{r subset}
m100_dt <- as.data.table(m100)
m100_dt[,year := year(date)]

#The following code breaks ties:
m100_yr <- m100_dt[, .(best_time = min(time), athlete = first(athlete)), by= year]

# #The following code does not choose a tie-breaker
m100_yr_dt <- merge(
  m100_dt,
  m100_dt[, .(best_time = min(time)), by = year],
  by.x = c("year", "time"),
  by.y = c("year", 'best_time')
  )

m100_yr %>% ggplot() + 
  geom_point(aes(x = as.numeric(year), y = best_time)) + 
  geom_point(subset(m100_yr, athlete == "Usain Bolt"), mapping = aes(x = as.numeric(year), y = best_time, color = "red")) + 
  scale_color_manual(values = "red", labels = "Usain Bolt") +
  labs(title = "100-Meter Run Times", x = "Date", y= "Best Time")


# m100_yr_dt %>% ggplot() + 
#   geom_point(aes(x = as.Date(date), y = time)) + 
#   geom_point(subset(m100_yr_dt, athlete == "Usain Bolt"), mapping = aes(x = as.Date(date), y = time, color = "red")) + 
#   scale_color_manual(values = "red", labels = "Usain Bolt") +
#   labs(title = "100-Meter Run Times", x = "Date", y= "Best Time")
```


## 6) Modeling and prediction

Imagine that you are back in the year **2005**. You are tasked with fitting a model of year-best 100m times up until that point. Importantly, your model will also be used to predict the trajectory of future 100m times.

### 6.1) Fit a model

Start by fitting a simple regression model of your choice, using data that would have been available to you then (you can include 2005). You are free to use whatever specification you prefer, but please be explicit by writing the model down. (Use dollar signs to demarcate LaTeX equations in R Markdown.) Please also show me the actual regression results in a nicely-formatted table.

*Hint: I'd advise excluding data from before 1975, since we don't have consecutive or consistent records before then.*
```{r lm}
#without windspeed
lm_2005 <- lm(best_time ~ year, data = m100_yr[year<=2005 & year>=1975])
summary(lm_2005)

#with windspeed, which turns out not to be statistically significant
# lm_2005.2 <- lm(time ~ year + windspeed, data = m100_yr_dt[year<=2005 & year>=1975])
# summary(lm_2005.2)

```
**I calculated the simple linear model with wind speed, but it wasn't statistically significant (even at the 10% level), so I omitted it. Instead, I have opted for the very basic**
$$best\_time_{i}=\alpha + \beta\cdot year_{i}+\epsilon_{i}$$

### 6.2) Prediction

Fast forward to the present day. Given your model and the available data in 2005, what year would you have predicted humanity reaching the current world record time of 9.58 seconds? How does this compare with the year that Usain Bolt actually set it (i.e. 2009). What do you make of this?
```{r predict}
# #Predicting using the rest of the data set
# #Doesn't reach Bolt's time, even in 2020
# predict(lm_2005, newdata = m100_yr[year>=1975][order(year)], interval = "prediction")

#Going far enough out, which I made sure of via solving by hand
predict(lm_2005, newdata = data.frame(year=2006:2036), interval = "prediction") %>% cbind(year=2006:2036) %>% tail(7)

```
**Based on the 2005 model, it would be expected that a time of 9.58s would be accomplished until around 2035, making 2009 Usain Bolt 26 years ahead of schedule. While not impossible, this certainly comes as a big surprise especially since (as we saw in the above graphs) no one else has approached these times since. Isn't there a Netflix documentary about Olympic doping?**


### 6.3) Plot your results

Provide a visual depiction of your prediction model. I basically want you to repeat your earlier plot from Question 4, but now with a (95 percent) prediction envelope. The prediction envelope should extend through both the "fitted" (<= 2005) _and_ "predicted" (2006--present) data periods. Make sure that these two periods are clearly demarcated in your plot.

*Hint: geom_smooth() isn't going to help you here because you need to predict out of sample.*
```{r predicted_plot}
m100_predictions <- broom::augment(lm_2005, newdata = m100_yr[year>=1975], interval = "prediction")

m100_predictions %>%
ggplot(aes(x = year, y = best_time, col = (year <= 2005), fill = (year <= 2005))) +
geom_point(alpha = 0.7) +
geom_line(aes(y = .fitted)) +
geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.2, col = NA) +
scale_color_discrete(name = "On/Before 2005?", aesthetics = c("colour", "fill")) + 
geom_point(subset(m100_yr, athlete == "Usain Bolt"), mapping = aes(x = year, y = best_time, color = "FALSE (Usain Bolt)")) +
labs(
title = "Predicting Best Time from Year",
caption = "Line of best fit predicted with data from 1975 : 2005 \n Includes 95% confidence/prediction bands",
y = "Best Time", 
x = "Year"
)

```


## 7) Map

### 7.1 Static map

Finally, go back to your original `m100` data frame, which contains all the data (i.e. not just the fastest time in each year). I want you to give me a sense of athletic achievement by country (including duplicate observations for the same athlete). Plot a world map, with a colour fill proportional to the number of fastest times that have been contributed by athletes of each country.

*Hint: Use the `sf`-compatible "countries" data frame from the `rnaturalearth` package that I showed you in the spatial lecture. This will come with a column of "iso_a3" country codes that you can match (i.e. join) to the "country" column of the `m100` data frame. There will likely be some mismatches because of inconsistencies in the ISO codes across these data frames. I won't be too strict about this, though you may find the `countrycode::countrycode()` function a helpful alternative.*
```{r static}
#Countries sf object
countries <- ne_countries(returnclass = "sf") %>% st_transform(8857) 

#Filtering out number of records, by country
#Then, reassigning country names
country_count_dt <- m100_dt[,.N, by = country][,country := countrycode::countrycode(country, "ioc", "iso3c")]
colnames(country_count_dt)[1] <- "iso_a3"

#Joining the two
number_records_sf <- left_join(countries, country_count_dt, by="iso_a3")

#Plotting
ggplot(number_records_sf) +
geom_sf(aes(color = N, fill = N), lwd = 0.3, col="white") +
scale_fill_viridis_c(name = "Number of Records") +
labs(title = "Men's 100m Records by Country", subtitle = "Equal Earth projection")
```


### 7.2. Interactive map

A major downside of the above static map is that some powerhouses of world athletics are geographically tiny nations in the Caribbean, which are very hard to see. One way to overcome this is to plot an interactive map using **leaflet** or one of the derivative packages that we discussed in the spatial lecture.
```{r interactive}
#Palette
col_pal <- colorNumeric("viridis", domain = number_records_sf$N)

#Plot
number_records_sf %>%
st_transform(crs = 4326) %>%
leaflet(width = "100%") %>%
addProviderTiles(provider = "CartoDB.Positron") %>%
addPolygons(
popup = ~paste0(iso_a3, "<br>", "Number of Records: ", prettyNum(N, big.mark=",")),
stroke = FALSE,
smoothFactor = 0,
fillOpacity = 0.7,
color = ~col_pal(N)
) %>%
addLegend(
"bottomright",
pal = col_pal,
values = ~N,
title = "Number of Records",
opacity = 1
)

```

